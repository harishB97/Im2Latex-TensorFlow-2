# Image2Latex-TF2
Tensorflow 2 implementation of Im2Markup model described in 2017  ICML paper "Image-to-Markup Generation with Coarse-to-Fine Attention"

The model has been built using the original implementation from [here](https://github.com/harvardnlp/im2markup) and Tensorflow-1 implementation from [here](https://github.com/aspnetcs/myim2latex-tensorflow-docker) as references.

Model Summary:

Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, None, None,  0                                            
__________________________________________________________________________________________________
tf.math.subtract (TFOpLambda)   (None, None, None, 1 0           input_1[0][0]                    
__________________________________________________________________________________________________
tf.math.truediv (TFOpLambda)    (None, None, None, 1 0           tf.math.subtract[0][0]           
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, None, None, 6 640         tf.math.truediv[0][0]            
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, None, None, 6 0           conv2d[0][0]                     
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, None, None, 1 73856       max_pooling2d[0][0]              
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, None, None, 2 295168      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, None, None, 2 1024        conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, None, None, 2 590080      batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, None, None, 2 0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, None, None, 5 1180160     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, None, None, 5 2048        conv2d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, None, None, 5 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, None, None, 5 2359808     max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, None, None, 5 2048        conv2d_5[0][0]                   
__________________________________________________________________________________________________
rnn (RNN)                       (None, None, None, 2 787456      batch_normalization_2[0][0]      
__________________________________________________________________________________________________
rnn_1 (RNN)                     (None, None, None, 2 787456      batch_normalization_2[0][0]      
__________________________________________________________________________________________________
tf.compat.v1.shape (TFOpLambda) (4,)                 0           rnn[0][0]                        
__________________________________________________________________________________________________
tf.compat.v1.shape_1 (TFOpLambd (4,)                 0           rnn[0][0]                        
__________________________________________________________________________________________________
tf.compat.v1.shape_2 (TFOpLambd (4,)                 0           rnn_1[0][0]                      
__________________________________________________________________________________________________
tf.compat.v1.shape_3 (TFOpLambd (4,)                 0           rnn_1[0][0]                      
__________________________________________________________________________________________________
tf.__operators__.getitem (Slici ()                   0           tf.compat.v1.shape[0][0]         
__________________________________________________________________________________________________
tf.__operators__.getitem_1 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       
__________________________________________________________________________________________________
tf.__operators__.getitem_2 (Sli ()                   0           tf.compat.v1.shape_2[0][0]       
__________________________________________________________________________________________________
tf.__operators__.getitem_3 (Sli ()                   0           tf.compat.v1.shape_3[0][0]       
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, None)]       0                                            
__________________________________________________________________________________________________
tf.reshape (TFOpLambda)         (None, None, None)   0           rnn[0][0]                        
                                                                 tf.__operators__.getitem[0][0]   
                                                                 tf.__operators__.getitem_1[0][0] 
__________________________________________________________________________________________________
tf.reshape_1 (TFOpLambda)       (None, None, None)   0           rnn_1[0][0]                      
                                                                 tf.__operators__.getitem_2[0][0] 
                                                                 tf.__operators__.getitem_3[0][0] 
__________________________________________________________________________________________________
embedding (Embedding)           (None, None, 80)     40320       input_2[0][0]                    
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None, None, 1536)] 0                                            
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, None, None)   0           tf.reshape[0][0]                 
                                                                 tf.reshape_1[0][0]               
__________________________________________________________________________________________________
rnn_2 (RNN)                     (None, None, None, 5 2258944     embedding[0][0]                  
                                                                 input_3[0][0]                    
                                                                 concatenate[0][0]                
==================================================================================================
Total params: 8,379,008
Trainable params: 8,376,448
Non-trainable params: 2,560
__________________________________________________________________________________________________

Download the tfrecord files from here and move to "100K_tfrecords_v3" folder for training.
