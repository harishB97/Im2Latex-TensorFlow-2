{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxwaaMw5qeYa",
    "outputId": "e446822a-677c-4f55-a464-dc2cabd32bf6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, Input, MaxPool2D, BatchNormalization, LSTM, concatenate, Softmax, RNN, ReLU, Dense\n",
    "from keras.layers import Lambda\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "print(tf.__version__) # 2.4.1\n",
    "print(tf.keras.__version__) # 2.4.0\n",
    "print(np.__version__) # 1.19.5\n",
    "\n",
    "tf.executing_eagerly() # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "JFo5wzh0q_R3"
   },
   "outputs": [],
   "source": [
    "H = 512\n",
    "W = 512\n",
    "C = 1\n",
    "vocab_size = 504\n",
    "embedding_dim = 80\n",
    "ENC_DIM = 256 # Hidden state dimension of encoder RNN\n",
    "DEC_DIM = 512 # Hidden state dimension of decoder RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIdN1verC_8_"
   },
   "source": [
    "# **Define all layers in the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "l5NaqPfGszuo"
   },
   "outputs": [],
   "source": [
    "layers = {}\n",
    "\n",
    "layers['conv1'] = Conv2D(filters=64, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['maxpool1'] = MaxPool2D(pool_size=[2, 2], strides=[2, 2])\n",
    "layers['conv2'] = Conv2D(filters=128, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['maxpool2'] = MaxPool2D(pool_size=[2, 2], strides=[2, 2])\n",
    "layers['conv3'] = Conv2D(filters=256, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['bn1'] = BatchNormalization()\n",
    "layers['conv4'] = Conv2D(filters=256, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['maxpool3'] = MaxPool2D(pool_size=[1, 2], strides=[1, 2])\n",
    "layers['conv5'] = Conv2D(filters=512, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['bn2'] = BatchNormalization()\n",
    "layers['maxpool4'] = MaxPool2D(pool_size=[2, 1], strides=[2, 1])\n",
    "layers['conv6'] = Conv2D(filters=512, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['bn3'] = BatchNormalization()\n",
    "\n",
    "\n",
    "class EncoderCell(keras.layers.Layer):\n",
    "    '''\n",
    "    Splits the convolution output vertically along height (dim == 1) and\n",
    "    runs RNN on each vertical cross section of conv output\n",
    "    '''\n",
    "    def __init__(self, encoder, state_size, output_size, **kwargs):\n",
    "        self.encoder = encoder\n",
    "        self.state_size = state_size\n",
    "        self.output_size = output_size\n",
    "        super(EncoderCell, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        self.built = True\n",
    " \n",
    "    def call(self, inputs, states):\n",
    "        output = self.encoder(inputs)\n",
    "        return output, states\n",
    "\n",
    "\n",
    "encoder_fw_cell = EncoderCell(LSTM(ENC_DIM, return_sequences=True), state_size=tf.TensorShape([1]), output_size=tf.TensorShape([None, ENC_DIM]))\n",
    "encoder_bw_cell = EncoderCell(LSTM(ENC_DIM, return_sequences=True, go_backwards=True), state_size=tf.TensorShape([1]), output_size=tf.TensorShape([None, ENC_DIM]))\n",
    "\n",
    "layers['encoder_fw'] = RNN(encoder_fw_cell, return_sequences=True)\n",
    "layers['encoder_bw'] = RNN(encoder_bw_cell, return_sequences=True)\n",
    "\n",
    "class AttentionCell(keras.layers.Layer):\n",
    "    '''\n",
    "    Bahdanau attention cell defined in https://arxiv.org/abs/1609.04938\n",
    "    '''\n",
    "    def __init__(self, input_embedding_size, decoder_out_shape, state_size, output_size, **kwargs):\n",
    "        self.input_embedding_size = input_embedding_size\n",
    "        self.decoder_out_shape = decoder_out_shape\n",
    "        self.state_size = state_size\n",
    "        self.output_size = output_size # vocab_size\n",
    "        super(AttentionCell, self).__init__(**kwargs)\n",
    "                \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.gates = self.add_weight(shape=(self.input_embedding_size[0]+512, 4*512),\n",
    "                                  initializer=tf.keras.initializers.GlorotUniform(),\n",
    "                                  trainable=True,\n",
    "                                  name='gates')  # (80+512, 4*512)\n",
    "        self.gates_bias = self.add_weight(shape=(1, 4*512),\n",
    "                                  initializer='zeros',\n",
    "                                  trainable=True,\n",
    "                                  name='gates_bias')  # (1, 4*512)\n",
    "        self.Wa = self.add_weight(shape=(self.decoder_out_shape[1], self.decoder_out_shape[1]),\n",
    "                                  initializer=tf.keras.initializers.GlorotUniform(),\n",
    "                                  trainable=True,\n",
    "                                  name='Wa')  # (512, 512)\n",
    "        self.Wc = self.add_weight(shape=(self.decoder_out_shape[1]*2, self.decoder_out_shape[1]),\n",
    "                                  initializer=tf.keras.initializers.GlorotUniform(),\n",
    "                                  trainable=True,\n",
    "                                  name='Wc')  # (512 + 512, 512) => (ENC_DIM*2 + DEC_DIM, DEC_DIM)\n",
    "        self.Ws = self.add_weight(shape=(self.decoder_out_shape[1], self.output_size[0]),\n",
    "                                  initializer=tf.keras.initializers.GlorotUniform(),\n",
    "                                  trainable=True,\n",
    "                                  name='Ws')  # (512, vocab_size)\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs, states):\n",
    "        \n",
    "        hs = states[1]\n",
    "        _, c_tm1, output_tm1 = tf.split(axis=-1, num_or_size_splits=3, value=states[0])\n",
    "        output_tm1 = tf.squeeze(output_tm1, axis=1)\n",
    "        xt = concatenate([inputs, output_tm1], axis=-1)\n",
    "        gates_out = tf.linalg.matmul(xt, self.gates) + self.gates_bias\n",
    "        i_t, f_t, o_t, g_t = tf.split(axis=-1, num_or_size_splits=4, value=gates_out)\n",
    "        \n",
    "        c_t = tf.math.sigmoid(f_t)*c_tm1 + tf.math.sigmoid(i_t)*tf.tanh(g_t)\n",
    "        h_t = tf.math.sigmoid(o_t)*tf.tanh(c_t)\n",
    "        \n",
    "        h_t = tf.expand_dims(h_t, axis=-1)\n",
    "        Wa_ht = tf.linalg.matmul(self.Wa, h_t)\n",
    "        score = tf.linalg.matmul(hs, Wa_ht)\n",
    "        score = tf.squeeze(score, axis=-1)\n",
    "        \n",
    "        at = Softmax(axis=-1)(score)\n",
    "        at = tf.expand_dims(at, axis=-2)\n",
    "        ct = tf.linalg.matmul(at, hs)\n",
    "\n",
    "        h_t = tf.squeeze(h_t, axis=-1)\n",
    "        h_t = tf.expand_dims(h_t, axis=-2)\n",
    "        ht_bar = tf.math.tanh(tf.linalg.matmul(tf.concat([ct, h_t], axis=-1), self.Wc))\n",
    "        Ws_ht_bar = tf.linalg.matmul(ht_bar, self.Ws)\n",
    "\n",
    "        output = tf.squeeze(Ws_ht_bar, axis=-2)\n",
    "        h_t = tf.squeeze(h_t, axis=-2)\n",
    "        ht_bar = tf.squeeze(ht_bar, axis=-2)\n",
    "\n",
    "        return output, [concatenate([h_t, c_t, ht_bar], axis=-1), hs]\n",
    "    \n",
    "\n",
    "layers['embedding'] = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
    "                                               embeddings_initializer=tf.keras.initializers.RandomNormal(stddev=1.0/np.sqrt(vocab_size)))\n",
    "\n",
    "layers['attention_cell'] = AttentionCell(input_embedding_size=tf.TensorShape([embedding_dim]), \n",
    "                            decoder_out_shape=tf.TensorShape([None, DEC_DIM]),\n",
    "                            state_size=[tf.TensorShape([1, DEC_DIM*3]), tf.TensorShape([None, ENC_DIM*2])], #tf.TensorShape([DEC_DIM*3]), \n",
    "                            output_size=tf.TensorShape([vocab_size]))\n",
    "\n",
    "layers['attention_layer'] = RNN(layers['attention_cell'], return_sequences=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iznAk7ADDlR2"
   },
   "source": [
    "# Build the model with the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "eLkud_kD1U18"
   },
   "outputs": [],
   "source": [
    "def build_model(image, latex_seq, decoder_initial_state, encoder_hid_st_input=None):\n",
    "    # encoder\n",
    "    img = image-128\n",
    "    img = img/128\n",
    "\n",
    "    x = layers['conv1'](img)\n",
    "    x = layers['maxpool1'](x)\n",
    "    # x -> (H/2, W/2, 64)\n",
    "\n",
    "    x = layers['conv2'](x)\n",
    "    x = layers['maxpool2'](x)\n",
    "    # x -> (H/4, W/4, 128)\n",
    "\n",
    "    x = layers['conv3'](x)\n",
    "    x = layers['bn1'](x)\n",
    "    # x -> (H/4, W/4, 256)\n",
    "\n",
    "    x = layers['conv4'](x)\n",
    "    x = layers['maxpool3'](x)\n",
    "    # x -> (H/4, W/8, 256)\n",
    "\n",
    "    x = layers['conv5'](x)\n",
    "    x = layers['bn2'](x)\n",
    "    x = layers['maxpool4'](x)\n",
    "    # x -> (H/8, W/8, 512)\n",
    "\n",
    "    x = layers['conv6'](x)\n",
    "    x = layers['bn3'](x)\n",
    "    # x -> (H/8, W/8, 512)\n",
    "    \n",
    "    encoder_fw_hid_st = layers['encoder_fw'](x)\n",
    "    encoder_fw_hid_st = tf.reshape(encoder_fw_hid_st,[tf.shape(encoder_fw_hid_st)[0],-1,tf.shape(encoder_fw_hid_st)[-1]])\n",
    "    \n",
    "    encoder_bw_hid_st = layers['encoder_bw'](x)\n",
    "    encoder_bw_hid_st = tf.reshape(encoder_bw_hid_st,[tf.shape(encoder_bw_hid_st)[0],-1,tf.shape(encoder_bw_hid_st)[-1]])\n",
    "\n",
    "    encoder_hid_st = concatenate([encoder_fw_hid_st, encoder_bw_hid_st], axis=-1)\n",
    "    \n",
    "    # decoder\n",
    "    if encoder_hid_st_input is None:\n",
    "        latex_emb = layers['embedding'](latex_seq)\n",
    "        logits = layers['attention_layer'](latex_emb, [decoder_initial_state, encoder_hid_st])\n",
    "        return keras.Model(inputs=[image, latex_seq, decoder_initial_state], outputs=logits)\n",
    "    else:\n",
    "        latex_emb = layers['embedding'](latex_seq)\n",
    "        decoder_hid_st = layers['decoder'](latex_emb)\n",
    "        latex_pred = layers['attention_layer'](decoder_hid_st, encoder_hid_st_input)\n",
    "        return keras.Model(inputs=image, outputs=encoder_hid_st), keras.Model(inputs=[latex_seq, encoder_hid_st_input], outputs=latex_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "KhpmIur45nrb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model? (y/n):n\n",
      "lr: 0.1\n",
      "clipnorm: 5.0\n",
      "optimizer: <keras.optimizer_v2.adam.Adam object at 0x000002231A988D30>\n",
      "x----------Model built----------x\n"
     ]
    }
   ],
   "source": [
    "load_model = input('Load model? (y/n):') == 'y'\n",
    "stage2_training_model = build_model(Input(shape=(None, None, C)), \n",
    "                                    Input(shape=tf.TensorShape([None])),\n",
    "                                    Input(shape=(None, DEC_DIM*3)),\n",
    "                                    None)\n",
    "if load_model:\n",
    "    stage2_training_model.load_weights('model_checkpoints_1/cp-0001.ckpt')\n",
    "    print(\"x----------Model loaded----------x\")\n",
    "\n",
    "lr = 0.1\n",
    "clipnorm = 5.0\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr, clipnorm=clipnorm)\n",
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "stage2_training_model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy', 'crossentropy'])\n",
    "stage2_training_model.optimizer.learning_rate.assign(lr)\n",
    "\n",
    "print('lr:', stage2_training_model.optimizer.learning_rate.numpy())\n",
    "print('clipnorm:', stage2_training_model.optimizer.clipnorm)\n",
    "print('optimizer:', stage2_training_model.optimizer)\n",
    "\n",
    "stage2_inference_encoder_model, stage2_inference_decoder_model = build_model(Input(shape=(H, W, C), batch_size=1), \n",
    "                                                                             Input(shape=tf.TensorShape([5]), batch_size=1),\n",
    "                                                                             Input(shape=(None, DEC_DIM*3))\n",
    "                                                                             Input(shape=(None, 512), batch_size=1))\n",
    "stage2_inference_encoder_model.compile()\n",
    "stage2_inference_decoder_model.compile()\n",
    "print(\"x----------Model built----------x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "kUT7dbNz6pU9"
   },
   "outputs": [],
   "source": [
    "# stage2_training_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YTmIYuVDqtp"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 1\n",
    "\n",
    "tfr_description = {\n",
    "        'image': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "        'latex_seq_in': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "        'latex_seq_out': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, tfr_description)\n",
    "\n",
    "def filter_long_seqs(sample_input, sample_output):\n",
    "    return tf.shape(sample_output)[-1] < 120\n",
    "\n",
    "def get_data(tfr_dir, subset, batch_size, filter_func=None):\n",
    "    files = tf.io.matching_files(os.path.join(tfr_dir, '{}_100K_??of??.tfrecord'.format(subset)))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    dataset = dataset.map(_parse_image_function)\n",
    "    dataset = dataset.map(lambda sample: ((tf.image.decode_jpeg(sample['image'][0]), sample['latex_seq_in']), sample['latex_seq_out']))\n",
    "    dataset = dataset.map(lambda input_, _: ((tf.cast(input_[0], dtype=tf.float32), tf.cast(input_[1], dtype=tf.float32)), _))\n",
    "    if filter_func is not None:\n",
    "        dataset = dataset.filter(filter_func)\n",
    "\n",
    "    dataset = dataset.padded_batch(batch_size, padding_values=((np.array(255, dtype=np.float32), np.array(0, dtype=np.float32)), np.array(0, dtype=np.int64)))\n",
    "    return dataset\n",
    "\n",
    "train_dataset = get_data(r'.\\100K_tfrecords_v3', 'train', batch_size=train_batch, filter_func=filter_long_seqs)\n",
    "val_dataset = get_data(r'.\\100K_tfrecords_v3', 'val', batch_size=train_batch)\n",
    "test_dataset = get_data(r'.\\100K_tfrecords_v3', 'test', batch_size=train_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_dataset:#.take(1):\n",
    "    img = batch[0][0]\n",
    "    latex_seq_in = batch[0][1]\n",
    "    latex_seq_out = batch[1]\n",
    "    cv2.imshow('img', img.numpy()[0].astype(np.uint8))\n",
    "    key_press = cv2.waitKey(0)\n",
    "    if key_press & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0\n",
    "checkpoint_path = r\"./model_checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True, # True\n",
    "                                                 verbose=0,\n",
    "                                                 save_freq=100)#'epoch')                    \n",
    "\n",
    "tbcallback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./tb_logs', histogram_freq=0, write_graph=False,\n",
    "    write_images=True, update_freq=100, profile_batch=0,\n",
    "    embeddings_freq=0, embeddings_metadata=None)\n",
    "\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.best_perp = np.iinfo(np.int32).max\n",
    "        self.step_count = 0\n",
    "        super(CustomCallback, self).__init__(**kwargs)\n",
    "        \n",
    "    def sum_of_gradients(self):\n",
    "        image = [abs(np.random.normal(size=(512, 512, 1))) for _ in range(1)]\n",
    "        img = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "        label = np.ones([1, 10])\n",
    "        support_class = tf.convert_to_tensor(label, dtype=tf.int64)\n",
    "        loss_fn = tf.losses.CategoricalCrossentropy()\n",
    "        grad_sum = None\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(img)\n",
    "            softmaxed = self.model((img, label))\n",
    "            loss = loss_fn(tf.one_hot(support_class, axis=-1, depth=504), softmaxed)\n",
    "        grads = tape.gradient(loss, img, unconnected_gradients=tf.UnconnectedGradients.NONE)\n",
    "        grad_sum = tf.reduce_sum(grads, axis=None).numpy()\n",
    "        \n",
    "        return grad_sum\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "        print('lr =', self.model.optimizer.learning_rate.numpy(), 'optimizer =', self.model.optimizer)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        mean_loss_train = np.mean(self.train_losses)\n",
    "        mean_perp_train = np.mean(list(map(lambda x: np.power(np.e,x), self.train_losses)))\n",
    "        print(\"Mean train loss:\", mean_loss_train,\",Mean train perplexity:\", mean_perp_train)\n",
    "        mean_loss_val = np.mean(self.val_losses)\n",
    "        mean_perp_val = np.mean(list(map(lambda x: np.power(np.e,x), self.val_losses)))\n",
    "        print(\"Mean val loss:\", mean_loss_val,\",Mean val perplexity:\", mean_perp_val)\n",
    "        if mean_perp_val < self.best_perp:\n",
    "            self.best_perp = mean_perp_val\n",
    "        else:\n",
    "            self.model.optimizer.learning_rate.assign(self.model.optimizer.learning_rate.numpy() / 2)\n",
    "        print(\"Best perplexity:\", self.best_perp)\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.train_losses.append(logs['loss'])\n",
    "        self.step_count += 1\n",
    "        \n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        self.val_losses.append(logs['loss'])\n",
    "\n",
    "custom_callback = CustomCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "stage2_training_model.fit(train_dataset, steps_per_epoch=None, # steps_per_epoch=None -> till dataset is exhausted\n",
    "                          epochs=initial_epoch+epochs, initial_epoch=initial_epoch,\n",
    "                          validation_data=val_dataset, validation_steps=None, # validation_steps=None -> till dataset is exhausted\n",
    "                          callbacks=[cp_callback, tbcallback, custom_callback])\n",
    "initial_epoch = initial_epoch+epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_metric(y_true, y_pred):\n",
    "    y_true = np.argmax(y_true, axis=-1)\n",
    "    y_true = np.expand_dims(y_true, axis=[1])\n",
    "    \n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    return corpus_bleu(y_true.tolist(), y_pred.tolist())\n",
    "    \n",
    "\n",
    "bleu_list = []\n",
    "test_itr = iter(test_dataset)\n",
    "\n",
    "for _ in range(test_size//train_batch):\n",
    "    batch = next(test_itr)\n",
    "    prediction = stage2_training_model.predict(batch[0])\n",
    "    bleu_list.append(bleu_metric(batch[1].numpy(), prediction))\n",
    "\n",
    "bleu = np.mean(bleu_list)\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwQ05kJ6D3mn"
   },
   "source": [
    "# Save the inference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIGDoKUzDLV3"
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(stage2_inference_encoder_model, \"stage2_inference_encoder_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mp-ciCSDSqG"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(stage2_inference_decoder_model)\n",
    "stage2_inference_decoder_model_tflite = converter.convert()\n",
    "with open('stage2_inference_decoder_model_tflite.tflite', 'wb') as f:\n",
    "  f.write(stage2_inference_decoder_model_tflite)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "stage2_model_2_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
