{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxwaaMw5qeYa",
    "outputId": "e446822a-677c-4f55-a464-dc2cabd32bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "2.4.0\n",
      "1.19.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.__version__ == 2.4.1\n",
    "# tf.keras.__version__ == 2.4.0\n",
    "# np.__version__ == 1.19.5\n",
    "# tf.executing_eagerly() == True\n",
    "# py version == 3.7.9\n",
    " \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, Input, MaxPool2D, BatchNormalization, LSTM, concatenate, Softmax, RNN\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from bleu_score import sentence_bleu, corpus_bleu\n",
    "from datetime import datetime\n",
    "# from nltk.translate.bleu_score import sentence_bleu\n",
    "# import nltk\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n",
    "print(np.__version__)\n",
    "\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JFo5wzh0q_R3"
   },
   "outputs": [],
   "source": [
    "H = None #700\n",
    "W = None #1500\n",
    "C = 1\n",
    "vocab_size = 503\n",
    "embedding_dim = 80\n",
    "ENC_DIM = 256 # Hidden state dimension of encoder RNN\n",
    "DEC_DIM = 512 # Hidden state dimension of decoder RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIdN1verC_8_"
   },
   "source": [
    "# **Define all layers in the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l5NaqPfGszuo"
   },
   "outputs": [],
   "source": [
    "layers = {}\n",
    "\n",
    "layers['conv1'] = Conv2D(filters=64, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['maxpool1'] = MaxPool2D(pool_size=[2, 2], strides=[2, 2])\n",
    "layers['conv2'] = Conv2D(filters=128, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['maxpool2'] = MaxPool2D(pool_size=[2, 2], strides=[2, 2])\n",
    "layers['conv3'] = Conv2D(filters=256, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['bn1'] = BatchNormalization()\n",
    "layers['conv4'] = Conv2D(filters=256, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['maxpool3'] = MaxPool2D(pool_size=[1, 2], strides=[1, 2])\n",
    "layers['conv5'] = Conv2D(filters=512, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['bn2'] = BatchNormalization()\n",
    "layers['maxpool4'] = MaxPool2D(pool_size=[2, 1], strides=[2, 1])\n",
    "layers['conv6'] = Conv2D(filters=512, kernel_size=[3, 3], padding='same', activation='relu')\n",
    "layers['bn3'] = BatchNormalization()\n",
    "\n",
    "\n",
    "class EncoderCell(keras.layers.Layer):\n",
    "    '''\n",
    "    Splits the convolution output vertically along height (dim == 1) and\n",
    "    runs RNN on each vertical cross section of conv output\n",
    "    '''\n",
    "    def __init__(self, encoder, state_size, output_size, **kwargs):\n",
    "        self.encoder = encoder\n",
    "        self.state_size = state_size\n",
    "        self.output_size = output_size\n",
    "        super(EncoderCell, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        self.built = True\n",
    " \n",
    "    def call(self, inputs, states):\n",
    "        output = self.encoder(inputs)\n",
    "        return output, states\n",
    "\n",
    "\n",
    "encoder_fw_cell = EncoderCell(LSTM(ENC_DIM, return_sequences=True), state_size=tf.TensorShape([1]), output_size=tf.TensorShape([None, ENC_DIM]))\n",
    "encoder_bw_cell = EncoderCell(LSTM(ENC_DIM, return_sequences=True, go_backwards=True), state_size=tf.TensorShape([1]), output_size=tf.TensorShape([None, ENC_DIM]))\n",
    "\n",
    "layers['encoder_fw'] = RNN(encoder_fw_cell, return_sequences=True)\n",
    "layers['encoder_bw'] = RNN(encoder_bw_cell, return_sequences=True)\n",
    "\n",
    "\n",
    "class AttentionCell(keras.layers.Layer):\n",
    " \n",
    "    def __init__(self, decoder_out_shape, state_size, output_size, **kwargs):\n",
    "        self.decoder_out_shape = decoder_out_shape\n",
    "        self.state_size = state_size # encoder_hid_st_shape\n",
    "        self.output_size = output_size\n",
    "        super(AttentionCell, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.Wa = self.add_weight(shape=(self.decoder_out_shape[1], self.decoder_out_shape[1]),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True,\n",
    "                                  name='Wa')  # (512, 512)\n",
    "        self.Ba = self.add_weight(shape=(self.decoder_out_shape[1], 1),\n",
    "                                  initializer='zeros',\n",
    "                                  trainable=True,\n",
    "                                  name='Ba')  # (512, 1)\n",
    "        \n",
    "        self.Wc = self.add_weight(shape=(self.state_size[1] + self.decoder_out_shape[1], self.decoder_out_shape[1]),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True,\n",
    "                                  name='Wc')  # (512 + 512, 512)\n",
    "        self.Bc = self.add_weight(shape=(1, self.decoder_out_shape[1]),\n",
    "                                  initializer='zeros',\n",
    "                                  trainable=True,\n",
    "                                  name='Bc')  # (1, 512)\n",
    " \n",
    "        self.Ws = self.add_weight(shape=(self.decoder_out_shape[1], self.output_size[0]),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True,\n",
    "                                  name='Ws')  # (512, vocab_size)\n",
    "        self.Bs = self.add_weight(shape=(1, self.output_size[0]),\n",
    "                                  initializer='zeros',\n",
    "                                  trainable=True,\n",
    "                                  name='Bs')  # (1, vocab_size)\n",
    "        \n",
    "        self.built = True\n",
    " \n",
    " \n",
    "    def call(self, inputs, states):\n",
    "        \n",
    "        ht = inputs\n",
    "        hs = states[0]\n",
    " \n",
    "        ht = tf.expand_dims(ht, axis=-1)\n",
    "        \n",
    "        Wa_ht = tf.linalg.matmul(self.Wa, ht) + self.Ba\n",
    "        score = tf.linalg.matmul(hs, Wa_ht)\n",
    "        score = tf.squeeze(score, axis=-1)\n",
    "        at = Softmax(axis=-1)(score)\n",
    "        at = tf.expand_dims(at, axis=-2)\n",
    "        ct = tf.linalg.matmul(at, hs)\n",
    "        ht = tf.squeeze(ht, axis=-1)\n",
    "        ht = tf.expand_dims(ht, axis=-2)\n",
    "        ht_bar = tf.math.tanh(tf.linalg.matmul(tf.concat([ct, ht], axis=-1), self.Wc) + self.Bc)\n",
    "        Ws_ht_bar = tf.linalg.matmul(ht_bar, self.Ws) + self.Bs\n",
    "        Ws_ht_bar = tf.squeeze(Ws_ht_bar, axis=-2)\n",
    "        output = Softmax(axis=-1)(Ws_ht_bar)\n",
    "        \n",
    "        return output, [hs]\n",
    "\n",
    "\n",
    "layers['embedding'] = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
    "layers['decoder'] = LSTM(DEC_DIM, return_sequences=True)\n",
    "cell = AttentionCell(decoder_out_shape=tf.TensorShape([None, DEC_DIM]), state_size=tf.TensorShape([None, ENC_DIM*2]),\n",
    "                     output_size=tf.TensorShape([vocab_size]))\n",
    "layers['attention_layer'] = RNN(cell, return_sequences=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iznAk7ADDlR2"
   },
   "source": [
    "# Build the model with the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eLkud_kD1U18"
   },
   "outputs": [],
   "source": [
    "def build_model(image, latex_seq, encoder_hid_st_input=None):\n",
    "    # encoder\n",
    "    img = image-128\n",
    "    img = img/128\n",
    "\n",
    "    x = layers['conv1'](img)\n",
    "    x = layers['maxpool1'](x)\n",
    "    # x -> (H/2, W/2, 64)\n",
    "\n",
    "    x = layers['conv2'](x)\n",
    "    x = layers['maxpool2'](x)\n",
    "    # x -> (H/4, W/4, 128)\n",
    "\n",
    "    x = layers['conv3'](x)\n",
    "    x = layers['bn1'](x)\n",
    "    # x -> (H/4, W/4, 256)\n",
    "\n",
    "    x = layers['conv4'](x)\n",
    "    x = layers['maxpool3'](x)\n",
    "    # x -> (H/4, W/8, 256)\n",
    "\n",
    "    x = layers['conv5'](x)\n",
    "    x = layers['bn2'](x)\n",
    "    x = layers['maxpool4'](x)\n",
    "    # x -> (H/8, W/8, 512)\n",
    "\n",
    "    x = layers['conv6'](x)\n",
    "    x = layers['bn3'](x)\n",
    "    # x -> (H/8, W/8, 512)\n",
    "\n",
    "    encoder_fw_hid_st = layers['encoder_fw'](x)\n",
    "    encoder_fw_hid_st = tf.reshape(encoder_fw_hid_st,[tf.shape(encoder_fw_hid_st)[0],-1,tf.shape(encoder_fw_hid_st)[-1]])\n",
    "\n",
    "    encoder_bw_hid_st = layers['encoder_bw'](x)\n",
    "    encoder_bw_hid_st = tf.reshape(encoder_bw_hid_st,[tf.shape(encoder_bw_hid_st)[0],-1,tf.shape(encoder_bw_hid_st)[-1]])\n",
    "\n",
    "    encoder_hid_st = concatenate([encoder_fw_hid_st, encoder_bw_hid_st], axis=-1)\n",
    "\n",
    "    # decoder\n",
    "    if encoder_hid_st_input is None:\n",
    "        latex_emb = layers['embedding'](latex_seq)\n",
    "        decoder_hid_st = layers['decoder'](latex_emb)\n",
    "        latex_pred = layers['attention_layer'](decoder_hid_st, encoder_hid_st)\n",
    "        print(latex_pred)\n",
    "        return keras.Model(inputs=[image, latex_seq], outputs=latex_pred)\n",
    "    else:\n",
    "        latex_emb = layers['embedding'](latex_seq)\n",
    "        decoder_hid_st = layers['decoder'](latex_emb)\n",
    "        latex_pred = layers['attention_layer'](decoder_hid_st, encoder_hid_st_input)\n",
    "\n",
    "        return keras.Model(inputs=image, outputs=encoder_hid_st), keras.Model(inputs=[latex_seq, encoder_hid_st_input], outputs=latex_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KhpmIur45nrb"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Load model? (y/n): y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, None, 503), dtype=tf.float32, name=None), name='rnn_2/transpose_1:0', description=\"created by layer 'rnn_2'\")\n",
      "x----------Model loaded----------x\n",
      "lr: 0.1\n",
      "clipnorm: 5.0\n",
      "optimizer: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f22180636d0>\n",
      "x----------Model built----------x\n"
     ]
    }
   ],
   "source": [
    "load_model = input('Load model? (y/n):') == 'y'\n",
    "stage2_training_model = build_model(Input(shape=(None, None, C)), \n",
    "                                    Input(shape=tf.TensorShape([None])), \n",
    "                                    None)\n",
    "if load_model:\n",
    "    stage2_training_model.load_weights('model_checkpoints_7/cp-0002.ckpt')\n",
    "    print(\"x----------Model loaded----------x\")\n",
    "\n",
    "lr = 0.1\n",
    "clipnorm = 5.0\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.0, nesterov=False, name='SGD', clipnorm=clipnorm)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr, clipnorm=5.0)\n",
    "stage2_training_model.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy', 'crossentropy'])\n",
    "stage2_training_model.optimizer.learning_rate.assign(lr)\n",
    "print('lr:', stage2_training_model.optimizer.learning_rate.numpy())\n",
    "print('clipnorm:', stage2_training_model.optimizer.clipnorm)\n",
    "print('optimizer:', stage2_training_model.optimizer)\n",
    "\n",
    "stage2_inference_encoder_model, stage2_inference_decoder_model = build_model(Input(shape=(H, W, C), batch_size=1), \n",
    "                                                                             Input(shape=tf.TensorShape([1]), batch_size=1), \n",
    "                                                                             Input(shape=(None, 512), batch_size=1))\n",
    "stage2_inference_encoder_model.compile()\n",
    "stage2_inference_decoder_model.compile()\n",
    "print(\"x----------Model built----------x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEL5RQJ_ec_w"
   },
   "source": [
    "# Check model with dummy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBrz5LnihobJ",
    "outputId": "13a14f8f-3a86-4dc0-d5c3-1ea6279cd081"
   },
   "outputs": [],
   "source": [
    "# y = np.ones((4, 10))\n",
    "# y = tf.one_hot(y, depth=vocab_size,axis=1)\n",
    "# y = tf.transpose(y, [0, 2, 1])\n",
    "# stage2_training_model.fit(x=[np.ones((4, 256, 256, 1)), np.ones((4, 10))], y=y, steps_per_epoch=2, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5XoOjpZfjc-",
    "outputId": "6a6a8cca-e5f0-473a-d6b8-144f82dbc575"
   },
   "outputs": [],
   "source": [
    "# batch_dummy = 1\n",
    "# img_dummy = np.ones((batch_dummy, 256, 256, 1))\n",
    "# latex_seq_dummy = np.ones((batch_dummy, 1))\n",
    "# train_output = stage2_training_model.predict(x=[img_dummy, latex_seq_dummy], batch_size=batch_dummy)\n",
    "# enc_output = stage2_inference_encoder_model.predict(x=img_dummy, batch_size=batch_dummy)\n",
    "# dec_output = stage2_inference_decoder_model.predict(x=[latex_seq_dummy, enc_output])\n",
    "\n",
    "# # print(train_output)\n",
    "# # print(dec_output)\n",
    "# print((train_output == dec_output).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YTmIYuVDqtp"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3GePLSyxe9gW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (((None, None, None, None), (None, None)), (None, None, 503)), types: ((tf.uint8, tf.int64), tf.float32)> samples: 76154\n",
      "<MapDataset shapes: (((None, None, None, None), (None, None)), (None, None, 503)), types: ((tf.uint8, tf.int64), tf.float32)> samples: 9297\n",
      "<MapDataset shapes: (((None, None, None, None), (None, None)), (None, None, 503)), types: ((tf.uint8, tf.int64), tf.float32)> samples: 10325\n"
     ]
    }
   ],
   "source": [
    "train_batch = 20\n",
    "\n",
    "tfr_description = {\n",
    "        'image': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "        'latex_seq_in': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "        'latex_seq_out': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, tfr_description)\n",
    "\n",
    "def filter_long_seqs(sample_input, sample_output):\n",
    "    return tf.shape(sample_output)[-1] < 120\n",
    "\n",
    "def get_data(tfr_dir, subset, batch_size=None, filter_func=None):\n",
    "    files = tf.io.matching_files(os.path.join(tfr_dir, '{}_100K_??of??.tfrecord'.format(subset)))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    dataset = dataset.map(_parse_image_function)\n",
    "    dataset = dataset.map(lambda sample: ((tf.image.decode_jpeg(sample['image'][0]), sample['latex_seq_in']), sample['latex_seq_out']))\n",
    "    if not filter_func is None:\n",
    "        dataset = dataset.filter(filter_func)\n",
    "    c = dataset.reduce(np.int64(0), lambda x, _: x + 1)\n",
    "    dataset = dataset.repeat().padded_batch(batch_size, padding_values=((np.array(255, dtype=np.uint8), np.array(0, dtype=np.int64)), np.array(0, dtype=np.int64)))\n",
    "    dataset = dataset.map(lambda _, latex_seq_out: (_, tf.one_hot(latex_seq_out, depth=vocab_size, axis=-1)))\n",
    "    return dataset, c\n",
    "\n",
    "train_dataset, train_size = get_data('./100K_tfrecords_2', 'train', batch_size=train_batch, filter_func=filter_long_seqs)\n",
    "val_dataset, val_size = get_data('./100K_tfrecords_2', 'val', batch_size=train_batch)\n",
    "test_dataset, test_size = get_data('./100K_tfrecords_2', 'test', batch_size=train_batch)\n",
    "print(train_dataset, \"samples:\", train_size.numpy())\n",
    "print(val_dataset, \"samples:\", val_size.numpy())\n",
    "print(test_dataset, \"samples:\", test_size.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = r\"./model_checkpoints_7/cp-{epoch:04d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=0,\n",
    "                                                 save_freq = 200)#'epoch')                    \n",
    "\n",
    "tbcallback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./tb_logs_7', histogram_freq=0, write_graph=False,\n",
    "    write_images=True, update_freq=200, profile_batch=0,\n",
    "    embeddings_freq=0, embeddings_metadata=None)\n",
    "\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.best_perp = 724.6295594167904 #np.iinfo(np.int32).max\n",
    "        super(CustomCallback, self).__init__(**kwargs)\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "        print('lr =', self.model.optimizer.learning_rate.numpy(), 'optimizer =', self.model.optimizer)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        mean_loss_train = np.mean(self.train_losses)\n",
    "        mean_perp_train = np.mean(list(map(lambda x: np.power(np.e,x), self.train_losses)))\n",
    "        print(\"Mean train loss:\", mean_loss_train,\",Mean train perplexity:\", mean_perp_train)\n",
    "        mean_loss_val = np.mean(self.val_losses)\n",
    "        mean_perp_val = np.mean(list(map(lambda x: np.power(np.e,x), self.val_losses)))\n",
    "        print(\"Mean val loss:\", mean_loss_val,\",Mean val perplexity:\", mean_perp_val)\n",
    "        if mean_perp_val < self.best_perp:\n",
    "            self.best_perp = mean_perp_val\n",
    "        else:s\n",
    "            self.model.optimizer.learning_rate.assign(self.model.optimizer.learning_rate.numpy() / 2)\n",
    "        print(\"Best perplexity:\", self.best_perp)\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.train_losses.append(logs['loss'])\n",
    "        \n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        self.val_losses.append(logs['loss'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "stage2_training_model.fit(train_dataset, steps_per_epoch=np.array(train_size//train_batch, dtype=np.int64),\n",
    "                          epochs=initial_epoch+epochs, initial_epoch=initial_epoch,\n",
    "                          validation_data=val_dataset, validation_steps=np.array(val_size//train_batch, dtype=np.int64),\n",
    "                          callbacks=[cp_callback, CustomCallback(), tbcallback])\n",
    "initial_epoch = initial_epoch+epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.575162558445461\n"
     ]
    }
   ],
   "source": [
    "def bleu_metric(y_true, y_pred):\n",
    "    y_true = np.argmax(y_true, axis=-1)\n",
    "    y_true = np.expand_dims(y_true, axis=[1])\n",
    "    \n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    return corpus_bleu(y_true.tolist(), y_pred.tolist())\n",
    "    \n",
    "\n",
    "bleu_list = []\n",
    "test_itr = iter(test_dataset)\n",
    "\n",
    "for _ in range(test_size//train_batch):\n",
    "    batch = next(test_itr)\n",
    "    prediction = stage2_training_model.predict(batch[0])\n",
    "    bleu_list.append(bleu_metric(batch[1].numpy(), prediction))\n",
    "\n",
    "bleu = np.mean(bleu_list)\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwQ05kJ6D3mn"
   },
   "source": [
    "# Save the inference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIGDoKUzDLV3"
   },
   "outputs": [],
   "source": [
    "# tf.saved_model.save(stage2_inference_encoder_model, \"stage2_inference_encoder_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mp-ciCSDSqG"
   },
   "outputs": [],
   "source": [
    "# converter = tf.lite.TFLiteConverter.from_keras_model(stage2_inference_decoder_model)\n",
    "# stage2_inference_decoder_model_tflite = converter.convert()\n",
    "# with open('stage2_inference_decoder_model_tflite.tflite', 'wb') as f:\n",
    "#   f.write(stage2_inference_decoder_model_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "stage2_model_2_1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
